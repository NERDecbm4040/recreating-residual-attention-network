{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7pOnFqISm_M"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (21.0)\n",
      "Requirement already satisfied: numpy in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (1.20.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (1.0.4)\n",
      "Requirement already satisfied: scipy in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (1.7.0)\n",
      "Requirement already satisfied: ipython in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (7.29.0)\n",
      "Requirement already satisfied: tensorboard in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (2.5.0)\n",
      "Requirement already satisfied: requests in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from keras-tuner) (2.26.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (0.18.0)\n",
      "Requirement already satisfied: colorama in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (5.0.9)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (3.0.19)\n",
      "Requirement already satisfied: pygments in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (52.0.0.post20210125)\n",
      "Requirement already satisfied: backcall in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (0.1.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from ipython->keras-tuner) (5.0.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from requests->keras-tuner) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from requests->keras-tuner) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from requests->keras-tuner) (1.26.5)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (1.34.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (3.17.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (1.33.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from tensorboard->keras-tuner) (0.36.2)\n",
      "Requirement already satisfied: six in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from absl-py>=0.4->tensorboard->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\intelpython3\\envs\\napari-env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner --upgrade\n",
    "# !pip uninstall requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2938,
     "status": "ok",
     "timestamp": 1638146762318,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "b2sUSTCuSpp9",
    "outputId": "d1bf0e09-22fe-4de8-b34c-f3f1740bb47e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\free_\\anaconda3\\envs\\napari-env\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\free_\\anaconda3\\envs\\napari-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\free_\\anaconda3\\envs\\napari-env\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "sns.set()\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\free_\\\\OneDrive\\\\Documents\\\\GitHub\\\\recreating-residual-attention-network\\\\nbks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1638146762318,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "_GevWrXFSLL0",
    "outputId": "8207e99f-e625-4a20-a882-e15384ccdd48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# If using Google Colab\n",
    "from google.colab import drive\n",
    "BASE_PATH = '/content/drive'\n",
    "drive.mount(BASE_PATH)\n",
    "\n",
    "# change directory\n",
    "import os\n",
    "PROJECT_PATH = os.path.join(BASE_PATH, \"MyDrive\", \"2021-09 Fall Semester\", \"ECBM 4040 Neural Network Deep Learning\", \"Project\", \"recreating-residual-attention-network\")\n",
    "os.chdir(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\free_\\OneDrive\\Documents\\GitHub\\recreating-residual-attention-network\n"
     ]
    }
   ],
   "source": [
    "#Jacob's path\n",
    "%cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1106,
     "status": "ok",
     "timestamp": 1638146763421,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "r_Acp3CnTb-s"
   },
   "outputs": [],
   "source": [
    "# Import created modules\n",
    "from src.models.ResidualAttentionNetworkAugment import ResidualAttentionNetwork\n",
    "from src.utils import generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAyyteqkTVSr"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for fixing an error with downloading the dataset (SSL Error) on Jupyter notebook when running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1638146768003,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "WPSJE3iFWm96"
   },
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = generate_data.get_cifar10_tensorslices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import created modules\n",
    "from src.models.ResidualAttentionNetwork import ResidualAttentionNetwork\n",
    "from src.utils import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, datagen = generate_data.get_cifar10(rotation_range=20,\n",
    "                                                                      width_shift_range=0.2,\n",
    "                                                                      height_shift_range=0.2,\n",
    "                                                                      horizontal_flip=True,\n",
    "                                                                      validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_im, train_iter_label = next(iter(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1638146768915,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "-W6MsnzwWm1_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (32, 32, 3)\n",
      "NUM_CLASS: 10\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = train_iter_im.shape[1:]\n",
    "NUM_CLASS = train_iter_label.shape[1]\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCH = 3\n",
    "print(f'Input Shape: {INPUT_SHAPE}')\n",
    "print(f'NUM_CLASS: {NUM_CLASS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = x_train.shape[1:]\n",
    "NUM_CLASS = y_train.shape[1]\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3268,
     "status": "ok",
     "timestamp": 1638142217346,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "nrskBka-4Pwu",
    "outputId": "06aac0e3-34c6-4ad0-d0e0-8b8f3aec8bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_attention_network_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           multiple                  864       \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "residual_unit_20 (ResidualUn multiple                  19520     \n",
      "_________________________________________________________________\n",
      "attention_module_2 (Attentio multiple                  347712    \n",
      "_________________________________________________________________\n",
      "residual_unit_30 (ResidualUn multiple                  96384     \n",
      "_________________________________________________________________\n",
      "attention_module_3 (Attentio multiple                  957184    \n",
      "_________________________________________________________________\n",
      "residual_unit_37 (ResidualUn multiple                  381184    \n",
      "_________________________________________________________________\n",
      "residual_unit_38 (ResidualUn multiple                  545024    \n",
      "_________________________________________________________________\n",
      "residual_unit_39 (ResidualUn multiple                  545024    \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat multiple                  2048      \n",
      "_________________________________________________________________\n",
      "re_lu_131 (ReLU)             multiple                  0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  16416     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 2,911,818\n",
      "Trainable params: 2,895,370\n",
      "Non-trainable params: 16,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = ResidualAttentionNetwork()\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 987441,
     "status": "ok",
     "timestamp": 1638143318067,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "YAIAb9XmXfyv",
    "outputId": "66a88fe0-48fc-485e-82cf-94141cd780ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 495s 781ms/step - loss: 1.8644 - accuracy: 0.3039 - val_loss: 1.8104 - val_accuracy: 0.3475\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 578s 925ms/step - loss: 1.7065 - accuracy: 0.3717 - val_loss: 2.0704 - val_accuracy: 0.2903\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 677s 1s/step - loss: 1.6014 - accuracy: 0.4152 - val_loss: 2.0208 - val_accuracy: 0.3537\n"
     ]
    }
   ],
   "source": [
    "model = ran_model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "500/500 [==============================] - 599s 1s/step - loss: 1.8632 - accuracy: 0.2951 - val_loss: 2.3271 - val_accuracy: 0.2371\n",
      "Epoch 2/3\n",
      "270/500 [===============>..............] - ETA: 5:56 - loss: 1.6187 - accuracy: 0.3945"
     ]
    }
   ],
   "source": [
    "model = ran_model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n",
    "                    validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n",
    "                    epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMk2PJXOJHWN"
   },
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246587,
     "status": "ok",
     "timestamp": 1638147346090,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "Er5LeKpO4d31",
    "outputId": "d47fd034-f6e6-45ab-a4d4-56658c5e260c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 42s 115ms/step - loss: 1.9136 - accuracy: 0.2836 - val_loss: 3.5685 - val_accuracy: 0.1610\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 1.5600 - accuracy: 0.4280 - val_loss: 1.6824 - val_accuracy: 0.3948\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1.4135 - accuracy: 0.4818 - val_loss: 1.8058 - val_accuracy: 0.3792\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 1.3094 - accuracy: 0.5275 - val_loss: 1.7367 - val_accuracy: 0.4007\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1.2209 - accuracy: 0.5610 - val_loss: 1.3163 - val_accuracy: 0.5300\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 1.1521 - accuracy: 0.5885 - val_loss: 1.3805 - val_accuracy: 0.5197\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1.0775 - accuracy: 0.6175 - val_loss: 1.6141 - val_accuracy: 0.4824\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 1.0129 - accuracy: 0.6403 - val_loss: 1.3127 - val_accuracy: 0.5444\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.9679 - accuracy: 0.6588 - val_loss: 1.0791 - val_accuracy: 0.6181\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.9186 - accuracy: 0.6779 - val_loss: 1.1483 - val_accuracy: 0.6088\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.8710 - accuracy: 0.6927 - val_loss: 0.9746 - val_accuracy: 0.6517\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.8375 - accuracy: 0.7065 - val_loss: 1.1259 - val_accuracy: 0.6283\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.7992 - accuracy: 0.7214 - val_loss: 1.8026 - val_accuracy: 0.4959\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.7777 - accuracy: 0.7266 - val_loss: 0.9180 - val_accuracy: 0.6809\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.7456 - accuracy: 0.7389 - val_loss: 0.8567 - val_accuracy: 0.7035\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 0.7237 - accuracy: 0.7473 - val_loss: 0.9915 - val_accuracy: 0.6679\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.7061 - accuracy: 0.7542 - val_loss: 0.8780 - val_accuracy: 0.6958\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.6774 - accuracy: 0.7629 - val_loss: 0.9320 - val_accuracy: 0.6811\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.6595 - accuracy: 0.7692 - val_loss: 0.9312 - val_accuracy: 0.6839\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.6458 - accuracy: 0.7741 - val_loss: 0.8402 - val_accuracy: 0.7187\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "model = ResidualAttentionNetwork()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n",
    "                    validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n",
    "                    epochs=n_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    ran_model = ResidualAttentionNetwork()\n",
    "    inputs = tf.keras.Input((32, 32, 3))\n",
    "    ran_model(inputs)\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4,1e-5])\n",
    "    ran_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "    return ran_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project NERD_dir\\NERD_Final_Project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from NERD_dir\\NERD_Final_Project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=25,\n",
    "                     factor=3,\n",
    "                     directory='NERD_dir',\n",
    "                     project_name='NERD_Final_Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create early stopping callback\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n",
    "#                     validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n",
    "#                     epochs=n_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 56s]\n",
      "val_accuracy: 0.4643999934196472\n",
      "\n",
      "Best val_accuracy So Far: 0.4643999934196472\n",
      "Total elapsed time: 00h 05m 47s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tuner.search(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=[stop_early])\n",
    "tuner.search(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), epochs=50, validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'), callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in NERD_dir\\NERD_Final_Project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.4643999934196472\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.30809998512268066\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.2904999852180481\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.15139999985694885\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary(num_trials=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "313/313 [==============================] - 42s 116ms/step - loss: 0.9126 - accuracy: 0.6770 - val_loss: 1.2114 - val_accuracy: 0.5960\n",
      "Epoch 2/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.8571 - accuracy: 0.6993 - val_loss: 1.1214 - val_accuracy: 0.6190\n",
      "Epoch 3/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.8262 - accuracy: 0.7107 - val_loss: 1.2021 - val_accuracy: 0.6079\n",
      "Epoch 4/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.7845 - accuracy: 0.7255 - val_loss: 1.1659 - val_accuracy: 0.6148\n",
      "Epoch 5/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.7568 - accuracy: 0.7365 - val_loss: 0.8808 - val_accuracy: 0.7013\n",
      "Epoch 6/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.7281 - accuracy: 0.7452 - val_loss: 0.8760 - val_accuracy: 0.7029\n",
      "Epoch 7/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.7098 - accuracy: 0.7527 - val_loss: 0.9100 - val_accuracy: 0.6946\n",
      "Epoch 8/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.6778 - accuracy: 0.7647 - val_loss: 0.9283 - val_accuracy: 0.6849\n",
      "Epoch 9/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.6626 - accuracy: 0.7673 - val_loss: 0.9021 - val_accuracy: 0.7016\n",
      "Epoch 10/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.6463 - accuracy: 0.7745 - val_loss: 0.8000 - val_accuracy: 0.7262\n",
      "Epoch 11/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.6249 - accuracy: 0.7828 - val_loss: 0.8146 - val_accuracy: 0.7194\n",
      "Epoch 12/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.6176 - accuracy: 0.7857 - val_loss: 0.7713 - val_accuracy: 0.7350\n",
      "Epoch 13/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5966 - accuracy: 0.7920 - val_loss: 1.2867 - val_accuracy: 0.6232\n",
      "Epoch 14/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5821 - accuracy: 0.7982 - val_loss: 0.7408 - val_accuracy: 0.7509\n",
      "Epoch 15/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5692 - accuracy: 0.8005 - val_loss: 0.7578 - val_accuracy: 0.7405\n",
      "Epoch 16/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.5625 - accuracy: 0.8057 - val_loss: 0.7917 - val_accuracy: 0.7306\n",
      "Epoch 17/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5454 - accuracy: 0.8104 - val_loss: 0.7481 - val_accuracy: 0.7460\n",
      "Epoch 18/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5394 - accuracy: 0.8127 - val_loss: 0.6598 - val_accuracy: 0.7690\n",
      "Epoch 19/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.5278 - accuracy: 0.8176 - val_loss: 0.6854 - val_accuracy: 0.7643\n",
      "Epoch 20/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.5185 - accuracy: 0.8200 - val_loss: 0.6955 - val_accuracy: 0.7653\n",
      "Epoch 21/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.5117 - accuracy: 0.8216 - val_loss: 0.6643 - val_accuracy: 0.7811\n",
      "Epoch 22/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.4993 - accuracy: 0.8255 - val_loss: 0.7696 - val_accuracy: 0.7462\n",
      "Epoch 23/75\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.4992 - accuracy: 0.8258 - val_loss: 0.6130 - val_accuracy: 0.7936\n",
      "Epoch 24/75\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.4804 - accuracy: 0.8325 - val_loss: 0.6278 - val_accuracy: 0.7880\n",
      "Epoch 25/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4696 - accuracy: 0.8371 - val_loss: 0.6071 - val_accuracy: 0.7919\n",
      "Epoch 26/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4740 - accuracy: 0.8367 - val_loss: 0.6204 - val_accuracy: 0.7965\n",
      "Epoch 27/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4581 - accuracy: 0.8404 - val_loss: 0.5945 - val_accuracy: 0.7977\n",
      "Epoch 28/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.4549 - accuracy: 0.8408 - val_loss: 0.5841 - val_accuracy: 0.8029\n",
      "Epoch 29/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.4504 - accuracy: 0.8433 - val_loss: 0.7583 - val_accuracy: 0.7484\n",
      "Epoch 30/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.4391 - accuracy: 0.8462 - val_loss: 0.6935 - val_accuracy: 0.7819\n",
      "Epoch 31/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4352 - accuracy: 0.8486 - val_loss: 0.6619 - val_accuracy: 0.7778\n",
      "Epoch 32/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.4292 - accuracy: 0.8500 - val_loss: 0.5775 - val_accuracy: 0.8022\n",
      "Epoch 33/75\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 0.4224 - accuracy: 0.8522 - val_loss: 0.5581 - val_accuracy: 0.8099\n",
      "Epoch 34/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.4220 - accuracy: 0.8529 - val_loss: 0.6336 - val_accuracy: 0.7943\n",
      "Epoch 35/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4111 - accuracy: 0.8562 - val_loss: 0.5632 - val_accuracy: 0.8115\n",
      "Epoch 36/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.4064 - accuracy: 0.8584 - val_loss: 0.5378 - val_accuracy: 0.8182\n",
      "Epoch 37/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.3982 - accuracy: 0.8598 - val_loss: 0.5569 - val_accuracy: 0.8155\n",
      "Epoch 38/75\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.3956 - accuracy: 0.8622 - val_loss: 0.5365 - val_accuracy: 0.8179\n",
      "Epoch 39/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3872 - accuracy: 0.8655 - val_loss: 0.5361 - val_accuracy: 0.8164\n",
      "Epoch 40/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3855 - accuracy: 0.8651 - val_loss: 0.5319 - val_accuracy: 0.8186\n",
      "Epoch 41/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.3795 - accuracy: 0.8687 - val_loss: 0.5949 - val_accuracy: 0.8054\n",
      "Epoch 42/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3780 - accuracy: 0.8690 - val_loss: 0.5508 - val_accuracy: 0.8161\n",
      "Epoch 43/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.3765 - accuracy: 0.8680 - val_loss: 0.5785 - val_accuracy: 0.8069\n",
      "Epoch 44/75\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.3660 - accuracy: 0.8719 - val_loss: 0.5450 - val_accuracy: 0.8198\n",
      "Epoch 45/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.3635 - accuracy: 0.8732 - val_loss: 0.6075 - val_accuracy: 0.7995\n",
      "Epoch 46/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3604 - accuracy: 0.8746 - val_loss: 0.5336 - val_accuracy: 0.8280\n",
      "Epoch 47/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3603 - accuracy: 0.8730 - val_loss: 0.5387 - val_accuracy: 0.8217\n",
      "Epoch 48/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.3524 - accuracy: 0.8754 - val_loss: 0.5941 - val_accuracy: 0.7990\n",
      "Epoch 49/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3433 - accuracy: 0.8799 - val_loss: 0.5409 - val_accuracy: 0.8179\n",
      "Epoch 50/75\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.3477 - accuracy: 0.8780 - val_loss: 0.5526 - val_accuracy: 0.8161\n",
      "Epoch 51/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3400 - accuracy: 0.8784 - val_loss: 0.5331 - val_accuracy: 0.8262\n",
      "Epoch 52/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3410 - accuracy: 0.8806 - val_loss: 0.5464 - val_accuracy: 0.8227\n",
      "Epoch 53/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3370 - accuracy: 0.8837 - val_loss: 0.5213 - val_accuracy: 0.8304\n",
      "Epoch 54/75\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.3316 - accuracy: 0.8857 - val_loss: 0.5433 - val_accuracy: 0.8204\n",
      "Epoch 55/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3245 - accuracy: 0.8869 - val_loss: 0.5441 - val_accuracy: 0.8244\n",
      "Epoch 56/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.3218 - accuracy: 0.8873 - val_loss: 0.6471 - val_accuracy: 0.7962\n",
      "Epoch 57/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3294 - accuracy: 0.8841 - val_loss: 0.5533 - val_accuracy: 0.8198\n",
      "Epoch 58/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3195 - accuracy: 0.8880 - val_loss: 0.5571 - val_accuracy: 0.8210\n",
      "Epoch 59/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3198 - accuracy: 0.8881 - val_loss: 0.5061 - val_accuracy: 0.8293\n",
      "Epoch 60/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3149 - accuracy: 0.8909 - val_loss: 0.5541 - val_accuracy: 0.8262\n",
      "Epoch 61/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3107 - accuracy: 0.8910 - val_loss: 0.5055 - val_accuracy: 0.8360\n",
      "Epoch 62/75\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.3020 - accuracy: 0.8922 - val_loss: 0.5085 - val_accuracy: 0.8353\n",
      "Epoch 63/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.3009 - accuracy: 0.8948 - val_loss: 0.5671 - val_accuracy: 0.8215\n",
      "Epoch 64/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.3017 - accuracy: 0.8937 - val_loss: 0.5791 - val_accuracy: 0.8177\n",
      "Epoch 65/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2970 - accuracy: 0.8956 - val_loss: 0.5438 - val_accuracy: 0.8244\n",
      "Epoch 66/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.2974 - accuracy: 0.8950 - val_loss: 0.6048 - val_accuracy: 0.8162\n",
      "Epoch 67/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2920 - accuracy: 0.8970 - val_loss: 0.5344 - val_accuracy: 0.8264\n",
      "Epoch 68/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2883 - accuracy: 0.9017 - val_loss: 0.5044 - val_accuracy: 0.8367\n",
      "Epoch 69/75\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.2830 - accuracy: 0.9010 - val_loss: 0.5739 - val_accuracy: 0.8192\n",
      "Epoch 70/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.2841 - accuracy: 0.9017 - val_loss: 0.5191 - val_accuracy: 0.8323\n",
      "Epoch 71/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2857 - accuracy: 0.8985 - val_loss: 0.4926 - val_accuracy: 0.8374\n",
      "Epoch 72/75\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.2781 - accuracy: 0.9021 - val_loss: 0.5023 - val_accuracy: 0.8351\n",
      "Epoch 73/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2725 - accuracy: 0.9049 - val_loss: 0.4985 - val_accuracy: 0.8431\n",
      "Epoch 74/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2773 - accuracy: 0.9014 - val_loss: 0.5355 - val_accuracy: 0.8236\n",
      "Epoch 75/75\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.2754 - accuracy: 0.9023 - val_loss: 0.5034 - val_accuracy: 0.8356\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 75\n",
    "\n",
    "model = ran_model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n",
    "                    validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n",
    "                    epochs=n_epochs, verbose=1)\n",
    "best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD7yCh0dWjid"
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model filename to save\n",
    "from datetime import datetime\n",
    "#include training params in model name\n",
    " \n",
    "model_filename = str(datetime.now) + '_model_' + 'EPOCHS_'+ str(n_epochs) + str(BATCH_SIZE)\n",
    "model_filepath = 'C:\\\\Users\\\\JacobNye\\\\Documents\\\\GitHub\\\\recreating-residual-attention-network\\\\data\\\\models\\\\'\n",
    "#model file path default is data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "ceqGmoDKTUNT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as add_23_layer_call_fn, add_23_layer_call_and_return_conditional_losses, conv2d_86_layer_call_fn, conv2d_86_layer_call_and_return_conditional_losses, re_lu_67_layer_call_fn while saving (showing 5 of 970). These functions will not be directly callable after loading.\n",
      "C:\\intelpython3\\envs\\napari-env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JacobNye\\Documents\\GitHub\\recreating-residual-attention-network\\data\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JacobNye\\Documents\\GitHub\\recreating-residual-attention-network\\data\\models\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save Model \n",
    "best_model.save(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test loading model\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model(model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPrVMPnsfw3HolQ9zr60/JK",
   "collapsed_sections": [],
   "name": "test_cifar10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "9572185e9b82452951e3e4d66be64da5c4a80b3cfbab518b2aeae2075ac06985"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
