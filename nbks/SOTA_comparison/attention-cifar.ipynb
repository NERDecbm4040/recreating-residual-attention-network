{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYJNBte6ywyx"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vt2mF-9ylH6",
    "outputId": "df1a73e7-6e35-4ab2-854f-e9384e8f6406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "sns.set()\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "from tensorflow import keras\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Joy5pYymy1eS",
    "outputId": "817fa4c3-e7c4-4777-962e-854bd0f53a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# If using Google Colab\n",
    "from google.colab import drive\n",
    "BASE_PATH = '/content/drive'\n",
    "drive.mount(BASE_PATH)\n",
    "\n",
    "# change directory\n",
    "import os\n",
    "PROJECT_PATH = os.path.join(BASE_PATH, \"MyDrive\", \"ECBM4040\", \"FinalProject\", \"recreating-residual-attention-network\")\n",
    "os.chdir(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZKnBQTCGh7V",
    "outputId": "4e0582b7-1c27-4ca6-c0d4-ba44ea765d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\free_\\OneDrive\\Documents\\GitHub\\recreating-residual-attention-network\n"
     ]
    }
   ],
   "source": [
    "#adjust filepath so that working directory is folder \"recreating-residual-attention-network\"\n",
    "%pwd\n",
    "%cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LvOmr1Eyy28a"
   },
   "outputs": [],
   "source": [
    "# Import created modules\n",
    "from src.models.ResidualAttentionNetwork import ResidualAttentionNetwork, Attention56, Attention92, Attention128, Attention164\n",
    "from src.utils import generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HsCtgLcy6Fa"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4kL-cGAdy-Sv"
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE, NUM_CLASS, train_ds, val_ds, test_ds, _ = generate_data.get_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q_GjVa2qzAkp"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "N_EPOCH = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Iq-54lS_-Dh_"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE*4).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(buffer_size=BATCH_SIZE*4).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE*4).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EB7v3UKK_EUB",
    "outputId": "3943d986-f9cf-4f60-ba18-e3fa9f03811f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  4 21:34:50 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkDFCeNs5X2E"
   },
   "source": [
    "## Naive Attention Learning vs Residual Attention Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYraP1xc5pkQ"
   },
   "source": [
    "### Naive Attention Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzhK0LIjzDjy",
    "outputId": "79e438f2-bfb8-4166-92df-6901482abfa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_attention_network\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             multiple                  864       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  multiple                 128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_unit (ResidualUnit  multiple                 6432      \n",
      " )                                                               \n",
      "                                                                 \n",
      " attention_module (Attention  multiple                 116608    \n",
      " Module)                                                         \n",
      "                                                                 \n",
      " residual_unit_13 (ResidualU  multiple                 24640     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_1 (Attenti  multiple                 347712    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_23 (ResidualU  multiple                 96384     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_2 (Attenti  multiple                 957184    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_30 (ResidualU  multiple                 381184    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_31 (ResidualU  multiple                 545024    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_32 (ResidualU  multiple                 545024    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " batch_normalization_106 (Ba  multiple                 2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_106 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  multiple                 0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,028,362\n",
      "Trainable params: 3,009,162\n",
      "Non-trainable params: 19,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = ResidualAttentionNetwork(input_shape=INPUT_SHAPE, num_class=NUM_CLASS, learning_type='nal')\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkEBXW9Iy5sJ",
    "outputId": "f7dc0a10-0d40-4578-893c-1aab2f82da1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 37s 110ms/step - loss: 2.4133 - accuracy: 0.1461 - val_loss: 2.5617 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 2.2672 - accuracy: 0.1830 - val_loss: 3.2553 - val_accuracy: 0.0950\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 2.1580 - accuracy: 0.2144 - val_loss: 2.3432 - val_accuracy: 0.2005\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 2.0650 - accuracy: 0.2461 - val_loss: 2.1246 - val_accuracy: 0.2459\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 15s 96ms/step - loss: 1.9930 - accuracy: 0.2685 - val_loss: 2.2023 - val_accuracy: 0.2280\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 1.9244 - accuracy: 0.2909 - val_loss: 2.0788 - val_accuracy: 0.2697\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 1.8702 - accuracy: 0.3154 - val_loss: 1.8306 - val_accuracy: 0.3351\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 1.8244 - accuracy: 0.3358 - val_loss: 1.9456 - val_accuracy: 0.3115\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 1.7840 - accuracy: 0.3532 - val_loss: 1.8543 - val_accuracy: 0.3437\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 1.7579 - accuracy: 0.3617 - val_loss: 1.8545 - val_accuracy: 0.3431\n"
     ]
    }
   ],
   "source": [
    "nal_model = ran_model\n",
    "\n",
    "nal_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = nal_model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMoo7v_Q5ti1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYSu67tk5uBy"
   },
   "source": [
    "### Residual Attention Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3sr_o_E5erl",
    "outputId": "af8816e9-2f0f-412e-bf11-836353363496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_attention_network_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         multiple                  864       \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  multiple                 128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_107 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " residual_unit_33 (ResidualU  multiple                 6432      \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_3 (Attenti  multiple                 116608    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_46 (ResidualU  multiple                 24640     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_4 (Attenti  multiple                 347712    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_56 (ResidualU  multiple                 96384     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_5 (Attenti  multiple                 957184    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_63 (ResidualU  multiple                 381184    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_64 (ResidualU  multiple                 545024    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_65 (ResidualU  multiple                 545024    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " batch_normalization_213 (Ba  multiple                 2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_213 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  multiple                 0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,028,362\n",
      "Trainable params: 3,009,162\n",
      "Non-trainable params: 19,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = ResidualAttentionNetwork(input_shape=INPUT_SHAPE, num_class=NUM_CLASS, learning_type='arl')\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fy88IU1bzNuq",
    "outputId": "5e587386-2ea2-4ef6-fd34-29d08efe1452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 64s 306ms/step - loss: 2.4113 - accuracy: 0.1523 - val_loss: 2.5067 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 45s 288ms/step - loss: 2.1210 - accuracy: 0.2495 - val_loss: 2.5251 - val_accuracy: 0.1268\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 45s 288ms/step - loss: 1.9903 - accuracy: 0.2894 - val_loss: 2.1483 - val_accuracy: 0.2473\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 46s 290ms/step - loss: 1.8977 - accuracy: 0.3189 - val_loss: 1.9694 - val_accuracy: 0.2904\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 1.8269 - accuracy: 0.3391 - val_loss: 1.7982 - val_accuracy: 0.3653\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 45s 288ms/step - loss: 1.7730 - accuracy: 0.3625 - val_loss: 1.7727 - val_accuracy: 0.3656\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 1.7417 - accuracy: 0.3726 - val_loss: 1.7011 - val_accuracy: 0.3927\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 1.7081 - accuracy: 0.3850 - val_loss: 1.7406 - val_accuracy: 0.3877\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 1.6826 - accuracy: 0.3922 - val_loss: 1.6307 - val_accuracy: 0.4140\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 45s 289ms/step - loss: 1.6656 - accuracy: 0.4004 - val_loss: 1.6952 - val_accuracy: 0.3976\n"
     ]
    }
   ],
   "source": [
    "arl_model = ran_model\n",
    "\n",
    "arl_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = arl_model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsebrvlmdvw8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qf9aDeJ6JQH"
   },
   "source": [
    "## Different number of attention module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZV1BC9vK6Y45"
   },
   "source": [
    "In this part, the experiment is done using Residual Attention Learning mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsOf7W_m6UZ5"
   },
   "source": [
    "### Attention-56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rc-qETCwmA6u",
    "outputId": "a5fdcd80-067d-4b18-b192-b12163b16a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention56_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         multiple                  864       \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  multiple                 128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_107 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " residual_unit_33 (ResidualU  multiple                 19520     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_3 (Attenti  multiple                 452352    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_46 (ResidualU  multiple                 96384     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_4 (Attenti  multiple                 1369216   \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_56 (ResidualU  multiple                 381184    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_5 (Attenti  multiple                 3798528   \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " residual_unit_63 (ResidualU  multiple                 1516032   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_64 (ResidualU  multiple                 2171392   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_65 (ResidualU  multiple                 2171392   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " batch_normalization_213 (Ba  multiple                 4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_213 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  multiple                 0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,991,338\n",
      "Trainable params: 11,953,002\n",
      "Non-trainable params: 38,336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = Attention56()\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "V6nA1olw8c5v",
    "outputId": "e6789b48-72a8-4a54-8ae5-ca0b3da94a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2615\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'Adam/Adam/update_420/ResourceApplyAdam/v' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fa74c30890e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m history = a56_model.fit(train_ds,\n\u001b[1;32m      9\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         epochs=N_EPOCH, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m-> 3129\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         if x is not None)\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2615\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2617\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2618\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2619\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a56_model = ran_model\n",
    "\n",
    "a56_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = a56_model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6SBfflndtCy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9D6JZpv6fyS"
   },
   "source": [
    "### Attention-92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lzh4OviZ6fIv",
    "outputId": "85281540-2c8f-4e4f-8108-3463a3a3a22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_417 (Conv2D)         multiple                  864       \n",
      "                                                                 \n",
      " batch_normalization_321 (Ba  multiple                 128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_321 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " residual_unit_99 (ResidualU  multiple                 19520     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " attention_module_9 (Attenti  multiple                 452352    \n",
      " onModule)                                                       \n",
      "                                                                 \n",
      " attention_module_10 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_124 (Residual  multiple                 96384     \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_11 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_12 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_143 (Residual  multiple                 381184    \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_13 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_14 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_156 (Residual  multiple                 1516032   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " residual_unit_157 (Residual  multiple                 2171392   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " residual_unit_158 (Residual  multiple                 2171392   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " batch_normalization_514 (Ba  multiple                 4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_514 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  multiple                 0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,611,434\n",
      "Trainable params: 17,548,778\n",
      "Non-trainable params: 62,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = Attention92()\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_V3KxO3T5zdv",
    "outputId": "ec239aba-9b7f-4227-905c-d02e6b1c6f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 68s 297ms/step - loss: 2.4021 - accuracy: 0.1148 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.3327 - accuracy: 0.1309 - val_loss: 2.3277 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 43s 277ms/step - loss: 2.3142 - accuracy: 0.1392 - val_loss: 2.3169 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.3007 - accuracy: 0.1388 - val_loss: 2.2687 - val_accuracy: 0.1425\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.2841 - accuracy: 0.1444 - val_loss: 2.2515 - val_accuracy: 0.1477\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.2747 - accuracy: 0.1508 - val_loss: 2.3620 - val_accuracy: 0.1074\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.2591 - accuracy: 0.1549 - val_loss: 2.6244 - val_accuracy: 0.0989\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.1532 - accuracy: 0.1896 - val_loss: 2.6195 - val_accuracy: 0.1270\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.0762 - accuracy: 0.2175 - val_loss: 2.4446 - val_accuracy: 0.1556\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 43s 276ms/step - loss: 2.0424 - accuracy: 0.2194 - val_loss: 2.2780 - val_accuracy: 0.1877\n"
     ]
    }
   ],
   "source": [
    "a92_model = ran_model\n",
    "\n",
    "a92_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = a92_model.fit(train_ds,\n",
    "                        validation_data=val_ds,\n",
    "                        epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXrvIm9KrqTI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4KnIPlArqyF"
   },
   "source": [
    "### Attention-128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcqhwWZRrpyq",
    "outputId": "a3fc9261-575d-4f5f-ae60-4af4e3e1d597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_3 (Sequential)   (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_670 (Conv2D)         multiple                  864       \n",
      "                                                                 \n",
      " batch_normalization_515 (Ba  multiple                 128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_515 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " residual_unit_159 (Residual  multiple                 19520     \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_15 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_16 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_17 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_196 (Residual  multiple                 96384     \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_18 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_19 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_20 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_224 (Residual  multiple                 381184    \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_21 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_22 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_23 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_243 (Residual  multiple                 1516032   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " residual_unit_244 (Residual  multiple                 2171392   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " residual_unit_245 (Residual  multiple                 2171392   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " batch_normalization_795 (Ba  multiple                 4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_795 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  multiple                 0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,231,530\n",
      "Trainable params: 23,144,554\n",
      "Non-trainable params: 86,976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = Attention128()\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXslNLPZruaS",
    "outputId": "4f7f2030-e27e-4ea0-eccc-02fa36a8786e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 97s 425ms/step - loss: 2.3997 - accuracy: 0.1120 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 62s 394ms/step - loss: 2.3201 - accuracy: 0.1385 - val_loss: 2.3081 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 62s 394ms/step - loss: 2.3025 - accuracy: 0.1425 - val_loss: 2.3207 - val_accuracy: 0.1014\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 2.2850 - accuracy: 0.1495 - val_loss: 2.2386 - val_accuracy: 0.1558\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 2.2778 - accuracy: 0.1456 - val_loss: 2.2371 - val_accuracy: 0.1636\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 62s 394ms/step - loss: 2.2649 - accuracy: 0.1521 - val_loss: 2.3654 - val_accuracy: 0.1311\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 2.2690 - accuracy: 0.1529 - val_loss: 2.3923 - val_accuracy: 0.1262\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 2.2531 - accuracy: 0.1548 - val_loss: 3.0107 - val_accuracy: 0.1535\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 2.2464 - accuracy: 0.1580 - val_loss: 2.2079 - val_accuracy: 0.1711\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 62s 393ms/step - loss: 2.2376 - accuracy: 0.1599 - val_loss: 2.2123 - val_accuracy: 0.1689\n"
     ]
    }
   ],
   "source": [
    "a128_model = ran_model\n",
    "\n",
    "a128_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                   loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = a128_model.fit(train_ds,\n",
    "                         validation_data=val_ds,\n",
    "                         epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ON-OSON-r2fj"
   },
   "source": [
    "### Attention-164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2dT297er3BC",
    "outputId": "df57e372-8e41-4f86-8a80-4bc270791051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_4 (Sequential)   (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d_1037 (Conv2D)        multiple                  864       \n",
      "                                                                 \n",
      " batch_normalization_796 (Ba  multiple                 128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_796 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " residual_unit_246 (Residual  multiple                 19520     \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_24 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_25 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_26 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_27 (Attent  multiple                 452352    \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_295 (Residual  multiple                 96384     \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_28 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_29 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_30 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_31 (Attent  multiple                 1369216   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_332 (Residual  multiple                 381184    \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " attention_module_32 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_33 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_34 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " attention_module_35 (Attent  multiple                 3798528   \n",
      " ionModule)                                                      \n",
      "                                                                 \n",
      " residual_unit_357 (Residual  multiple                 1516032   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " residual_unit_358 (Residual  multiple                 2171392   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " residual_unit_359 (Residual  multiple                 2171392   \n",
      " Unit)                                                           \n",
      "                                                                 \n",
      " batch_normalization_1163 (B  multiple                 4096      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " re_lu_1163 (ReLU)           multiple                  0         \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  multiple                 0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,851,626\n",
      "Trainable params: 28,740,330\n",
      "Non-trainable params: 111,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran_model = Attention164()\n",
    "inputs = tf.keras.Input((32, 32, 3))\n",
    "ran_model(inputs)\n",
    "ran_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "xN_rU059r3c5",
    "outputId": "52a46f02-3a74-4fd8-8244-4877abe19fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 98s 425ms/step - loss: 2.1079 - accuracy: 0.1941 - val_loss: 2.1368 - val_accuracy: 0.1748\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 62s 395ms/step - loss: 1.9617 - accuracy: 0.2410 - val_loss: 2.9659 - val_accuracy: 0.1587\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 62s 395ms/step - loss: 1.9016 - accuracy: 0.2630 - val_loss: 3.4470 - val_accuracy: 0.1594\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3b35fd353949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m history = a164_model.fit(train_ds,\n\u001b[1;32m      9\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                          epochs=N_EPOCH, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1203\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a164_model = ran_model\n",
    "\n",
    "a164_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                   loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = a164_model.fit(train_ds,\n",
    "                         validation_data=val_ds,\n",
    "                         epochs=N_EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide ResNet Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "multi_arch-cifar10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
