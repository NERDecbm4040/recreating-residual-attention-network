{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"multi_arch-cifar10.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOxg/MyX2/5Q0o8sSmwLq0P"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rYJNBte6ywyx"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vt2mF-9ylH6","executionInfo":{"status":"ok","timestamp":1638628324746,"user_tz":300,"elapsed":4084,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"ec95306b-29bb-44b8-fa4e-8ce6385f9d28"},"source":["# data processing\n","import numpy as np\n","import pandas as pd \n","from collections import defaultdict\n","\n","# data visualization\n","import seaborn as sns\n","%config InlineBackend.figure_format = 'retina'\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","from matplotlib import style\n","sns.set()\n","import urllib.request\n","\n","\n","import tensorflow as tf\n","print(tf.config.list_physical_devices('GPU'))\n","from tensorflow import keras\n","\n","# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Joy5pYymy1eS","executionInfo":{"status":"ok","timestamp":1638628421803,"user_tz":300,"elapsed":25074,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"f4fc49c1-bd40-4065-e875-1ae8e3121c22"},"source":["# If using Google Colab\n","from google.colab import drive\n","BASE_PATH = '/content/drive'\n","drive.mount(BASE_PATH)\n","\n","# change directory\n","import os\n","PROJECT_PATH = os.path.join(BASE_PATH, \"MyDrive\", \"2021-09 Fall Semester\", \"ECBM 4040 Neural Network Deep Learning\", \"Project\", \"recreating-residual-attention-network\")\n","os.chdir(PROJECT_PATH)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"LvOmr1Eyy28a","executionInfo":{"status":"ok","timestamp":1638628439978,"user_tz":300,"elapsed":12065,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}}},"source":["# Import created modules\n","from src.models.ResidualAttentionNetwork import ResidualAttentionNetwork, Attention56, Attention92, Attention128, Attention164\n","from src.utils import generate_data"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HsCtgLcy6Fa"},"source":["# Modelling"]},{"cell_type":"code","metadata":{"id":"4kL-cGAdy-Sv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638628460533,"user_tz":300,"elapsed":16885,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"2d038daf-0dde-409c-d6dd-b6b89ffea8d4"},"source":["INPUT_SHAPE, NUM_CLASS, train_ds, val_ds, test_ds, _ = generate_data.get_cifar10()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n","170508288/170498071 [==============================] - 11s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"q_GjVa2qzAkp","executionInfo":{"status":"ok","timestamp":1638628460535,"user_tz":300,"elapsed":6,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}}},"source":["BATCH_SIZE = 256\n","N_EPOCH = 10\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iq-54lS_-Dh_","executionInfo":{"status":"ok","timestamp":1638628460535,"user_tz":300,"elapsed":5,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}}},"source":["train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE*4).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_ds = val_ds.shuffle(buffer_size=BATCH_SIZE*4).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n","test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE*4).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"EB7v3UKK_EUB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkDFCeNs5X2E"},"source":["## Naive Attention Learning vs Residual Attention Learning"]},{"cell_type":"markdown","metadata":{"id":"WYraP1xc5pkQ"},"source":["### Naive Attention Learning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzhK0LIjzDjy","executionInfo":{"status":"ok","timestamp":1638628467082,"user_tz":300,"elapsed":6551,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"efcf8a04-59d4-48e8-e0e5-7e6183257ea8"},"source":["ran_model = ResidualAttentionNetwork(input_shape=INPUT_SHAPE, num_class=NUM_CLASS, learning_type='nal')\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"residual_attention_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential (Sequential)     (None, 32, 32, 3)         0         \n","                                                                 \n"," conv2d (Conv2D)             multiple                  864       \n","                                                                 \n"," batch_normalization (BatchN  multiple                 128       \n"," ormalization)                                                   \n","                                                                 \n"," re_lu (ReLU)                multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," residual_unit (ResidualUnit  multiple                 6432      \n"," )                                                               \n","                                                                 \n"," attention_module (Attention  multiple                 116608    \n"," Module)                                                         \n","                                                                 \n"," residual_unit_13 (ResidualU  multiple                 24640     \n"," nit)                                                            \n","                                                                 \n"," attention_module_1 (Attenti  multiple                 347712    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_23 (ResidualU  multiple                 96384     \n"," nit)                                                            \n","                                                                 \n"," attention_module_2 (Attenti  multiple                 957184    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_30 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_31 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_32 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_106 (Ba  multiple                 2048      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_106 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d (AverageP  multiple                 0         \n"," ooling2D)                                                       \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  5130      \n","                                                                 \n","=================================================================\n","Total params: 3,028,362\n","Trainable params: 3,009,162\n","Non-trainable params: 19,200\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YkEBXW9Iy5sJ","executionInfo":{"status":"ok","timestamp":1638629134237,"user_tz":300,"elapsed":667161,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"6cc3e8e2-bb09-4242-81f9-d744e4c3f58d"},"source":["nal_model = ran_model\n","\n","nal_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = nal_model.fit(train_ds,\n","                        validation_data=val_ds,\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 75s 315ms/step - loss: 2.4122 - accuracy: 0.1538 - val_loss: 2.4336 - val_accuracy: 0.0839\n","Epoch 2/10\n","157/157 [==============================] - 45s 288ms/step - loss: 2.1877 - accuracy: 0.2224 - val_loss: 2.7091 - val_accuracy: 0.1459\n","Epoch 3/10\n","157/157 [==============================] - 45s 286ms/step - loss: 2.0631 - accuracy: 0.2672 - val_loss: 2.3955 - val_accuracy: 0.2169\n","Epoch 4/10\n","157/157 [==============================] - 45s 288ms/step - loss: 1.9851 - accuracy: 0.2907 - val_loss: 1.9223 - val_accuracy: 0.3110\n","Epoch 5/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.9185 - accuracy: 0.3146 - val_loss: 1.9016 - val_accuracy: 0.3278\n","Epoch 6/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.8648 - accuracy: 0.3274 - val_loss: 1.9299 - val_accuracy: 0.3428\n","Epoch 7/10\n","157/157 [==============================] - 45s 288ms/step - loss: 1.8251 - accuracy: 0.3427 - val_loss: 1.8776 - val_accuracy: 0.3286\n","Epoch 8/10\n","157/157 [==============================] - 45s 287ms/step - loss: 1.7870 - accuracy: 0.3534 - val_loss: 1.7959 - val_accuracy: 0.3611\n","Epoch 9/10\n","157/157 [==============================] - 45s 287ms/step - loss: 1.7602 - accuracy: 0.3637 - val_loss: 1.6564 - val_accuracy: 0.4093\n","Epoch 10/10\n","157/157 [==============================] - 45s 286ms/step - loss: 1.7321 - accuracy: 0.3720 - val_loss: 1.8470 - val_accuracy: 0.3562\n"]}]},{"cell_type":"code","metadata":{"id":"DMoo7v_Q5ti1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYSu67tk5uBy"},"source":["### Residual Attention Learning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3sr_o_E5erl","executionInfo":{"status":"ok","timestamp":1638629137196,"user_tz":300,"elapsed":2966,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"0986e8ca-62a2-442f-db56-266d20c7167e"},"source":["ran_model = ResidualAttentionNetwork(input_shape=INPUT_SHAPE, num_class=NUM_CLASS, learning_type='arl')\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"residual_attention_network_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential (Sequential)     (None, 32, 32, 3)         0         \n","                                                                 \n"," conv2d_139 (Conv2D)         multiple                  864       \n","                                                                 \n"," batch_normalization_107 (Ba  multiple                 128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_107 (ReLU)            multiple                  0         \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," residual_unit_33 (ResidualU  multiple                 6432      \n"," nit)                                                            \n","                                                                 \n"," attention_module_3 (Attenti  multiple                 116608    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_46 (ResidualU  multiple                 24640     \n"," nit)                                                            \n","                                                                 \n"," attention_module_4 (Attenti  multiple                 347712    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_56 (ResidualU  multiple                 96384     \n"," nit)                                                            \n","                                                                 \n"," attention_module_5 (Attenti  multiple                 957184    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_63 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_64 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_65 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_213 (Ba  multiple                 2048      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_213 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d_1 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_1 (Flatten)         multiple                  0         \n","                                                                 \n"," dense_1 (Dense)             multiple                  5130      \n","                                                                 \n","=================================================================\n","Total params: 3,028,362\n","Trainable params: 3,009,162\n","Non-trainable params: 19,200\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"fy88IU1bzNuq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638629828440,"user_tz":300,"elapsed":691247,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"5e587386-2ea2-4ef6-fd34-29d08efe1452"},"source":["arl_model = ran_model\n","\n","arl_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = arl_model.fit(train_ds,\n","                        validation_data=val_ds,\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 64s 306ms/step - loss: 2.4113 - accuracy: 0.1523 - val_loss: 2.5067 - val_accuracy: 0.1000\n","Epoch 2/10\n","157/157 [==============================] - 45s 288ms/step - loss: 2.1210 - accuracy: 0.2495 - val_loss: 2.5251 - val_accuracy: 0.1268\n","Epoch 3/10\n","157/157 [==============================] - 45s 288ms/step - loss: 1.9903 - accuracy: 0.2894 - val_loss: 2.1483 - val_accuracy: 0.2473\n","Epoch 4/10\n","157/157 [==============================] - 46s 290ms/step - loss: 1.8977 - accuracy: 0.3189 - val_loss: 1.9694 - val_accuracy: 0.2904\n","Epoch 5/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.8269 - accuracy: 0.3391 - val_loss: 1.7982 - val_accuracy: 0.3653\n","Epoch 6/10\n","157/157 [==============================] - 45s 288ms/step - loss: 1.7730 - accuracy: 0.3625 - val_loss: 1.7727 - val_accuracy: 0.3656\n","Epoch 7/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.7417 - accuracy: 0.3726 - val_loss: 1.7011 - val_accuracy: 0.3927\n","Epoch 8/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.7081 - accuracy: 0.3850 - val_loss: 1.7406 - val_accuracy: 0.3877\n","Epoch 9/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.6826 - accuracy: 0.3922 - val_loss: 1.6307 - val_accuracy: 0.4140\n","Epoch 10/10\n","157/157 [==============================] - 45s 289ms/step - loss: 1.6656 - accuracy: 0.4004 - val_loss: 1.6952 - val_accuracy: 0.3976\n"]}]},{"cell_type":"code","metadata":{"id":"bsebrvlmdvw8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_qf9aDeJ6JQH"},"source":["## Different number of attention module"]},{"cell_type":"markdown","metadata":{"id":"ZV1BC9vK6Y45"},"source":["In this part, the experiment is done using Residual Attention Learning mechanism"]},{"cell_type":"markdown","metadata":{"id":"XsOf7W_m6UZ5"},"source":["### Attention-56"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc-qETCwmA6u","executionInfo":{"status":"ok","timestamp":1638629831600,"user_tz":300,"elapsed":2893,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"6233d5a7-faa4-46f2-9aba-13f150540e4d"},"source":["ran_model = Attention56()\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"attention56\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_1 (Sequential)   (None, 32, 32, 3)         0         \n","                                                                 \n"," conv2d_278 (Conv2D)         multiple                  864       \n","                                                                 \n"," batch_normalization_214 (Ba  multiple                 128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_214 (ReLU)            multiple                  0         \n","                                                                 \n"," max_pooling2d_14 (MaxPoolin  multiple                 0         \n"," g2D)                                                            \n","                                                                 \n"," residual_unit_66 (ResidualU  multiple                 19520     \n"," nit)                                                            \n","                                                                 \n"," attention_module_6 (Attenti  multiple                 452352    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_79 (ResidualU  multiple                 96384     \n"," nit)                                                            \n","                                                                 \n"," attention_module_7 (Attenti  multiple                 1369216   \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_89 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," attention_module_8 (Attenti  multiple                 3798528   \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_96 (ResidualU  multiple                 1516032   \n"," nit)                                                            \n","                                                                 \n"," residual_unit_97 (ResidualU  multiple                 2171392   \n"," nit)                                                            \n","                                                                 \n"," residual_unit_98 (ResidualU  multiple                 2171392   \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_320 (Ba  multiple                 4096      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_320 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d_2 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_2 (Flatten)         multiple                  0         \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," dense_2 (Dense)             multiple                  10250     \n","                                                                 \n","=================================================================\n","Total params: 11,991,338\n","Trainable params: 11,953,002\n","Non-trainable params: 38,336\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"V6nA1olw8c5v","executionInfo":{"status":"error","timestamp":1638513308054,"user_tz":300,"elapsed":246374,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"5a7a932c-7b94-408b-e93a-a8855d1c9d15"},"source":["a56_model = ran_model\n","\n","a56_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = a56_model.fit(train_ds,\n","                        validation_data=val_ds,\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 235s 1s/step - loss: 2.5170 - accuracy: 0.1221 - val_loss: 2.4114 - val_accuracy: 0.1000\n","Epoch 2/10\n","  8/157 [>.............................] - ETA: 3:00 - loss: 2.3873 - accuracy: 0.1514"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-fa74c30890e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m history = a56_model.fit(train_ds,\n\u001b[1;32m      9\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         epochs=N_EPOCH, verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"x6SBfflndtCy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9D6JZpv6fyS"},"source":["### Attention-92"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lzh4OviZ6fIv","executionInfo":{"status":"ok","timestamp":1638629837100,"user_tz":300,"elapsed":5502,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"9a21e481-cb4d-4764-83b2-562125f3bbd9"},"source":["ran_model = Attention92()\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"attention92\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_2 (Sequential)   (None, 32, 32, 3)         0         \n","                                                                 \n"," conv2d_417 (Conv2D)         multiple                  864       \n","                                                                 \n"," batch_normalization_321 (Ba  multiple                 128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_321 (ReLU)            multiple                  0         \n","                                                                 \n"," max_pooling2d_21 (MaxPoolin  multiple                 0         \n"," g2D)                                                            \n","                                                                 \n"," residual_unit_99 (ResidualU  multiple                 19520     \n"," nit)                                                            \n","                                                                 \n"," attention_module_9 (Attenti  multiple                 452352    \n"," onModule)                                                       \n","                                                                 \n"," attention_module_10 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_124 (Residual  multiple                 96384     \n"," Unit)                                                           \n","                                                                 \n"," attention_module_11 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_12 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_143 (Residual  multiple                 381184    \n"," Unit)                                                           \n","                                                                 \n"," attention_module_13 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_14 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_156 (Residual  multiple                 1516032   \n"," Unit)                                                           \n","                                                                 \n"," residual_unit_157 (Residual  multiple                 2171392   \n"," Unit)                                                           \n","                                                                 \n"," residual_unit_158 (Residual  multiple                 2171392   \n"," Unit)                                                           \n","                                                                 \n"," batch_normalization_514 (Ba  multiple                 4096      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_514 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d_3 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_3 (Flatten)         multiple                  0         \n","                                                                 \n"," dropout_1 (Dropout)         multiple                  0         \n","                                                                 \n"," dense_3 (Dense)             multiple                  10250     \n","                                                                 \n","=================================================================\n","Total params: 17,611,434\n","Trainable params: 17,548,778\n","Non-trainable params: 62,656\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"_V3KxO3T5zdv"},"source":["a92_model = ran_model\n","\n","a92_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = a92_model.fit(train_ds,\n","                        validation_data=val_ds,\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXrvIm9KrqTI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I4KnIPlArqyF"},"source":["### Attention-128"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcqhwWZRrpyq","executionInfo":{"status":"ok","timestamp":1638629844159,"user_tz":300,"elapsed":7062,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"6894f879-d03e-4d11-ea6f-4aeebb11d92e"},"source":["ran_model = Attention128()\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"attention128\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_3 (Sequential)   (None, 32, 32, 3)         0         \n","                                                                 \n"," conv2d_670 (Conv2D)         multiple                  864       \n","                                                                 \n"," batch_normalization_515 (Ba  multiple                 128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_515 (ReLU)            multiple                  0         \n","                                                                 \n"," max_pooling2d_34 (MaxPoolin  multiple                 0         \n"," g2D)                                                            \n","                                                                 \n"," residual_unit_159 (Residual  multiple                 19520     \n"," Unit)                                                           \n","                                                                 \n"," attention_module_15 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_16 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_17 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_196 (Residual  multiple                 96384     \n"," Unit)                                                           \n","                                                                 \n"," attention_module_18 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_19 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_20 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_224 (Residual  multiple                 381184    \n"," Unit)                                                           \n","                                                                 \n"," attention_module_21 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_22 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_23 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_243 (Residual  multiple                 1516032   \n"," Unit)                                                           \n","                                                                 \n"," residual_unit_244 (Residual  multiple                 2171392   \n"," Unit)                                                           \n","                                                                 \n"," residual_unit_245 (Residual  multiple                 2171392   \n"," Unit)                                                           \n","                                                                 \n"," batch_normalization_795 (Ba  multiple                 4096      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_795 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d_4 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_4 (Flatten)         multiple                  0         \n","                                                                 \n"," dropout_2 (Dropout)         multiple                  0         \n","                                                                 \n"," dense_4 (Dense)             multiple                  10250     \n","                                                                 \n","=================================================================\n","Total params: 23,231,530\n","Trainable params: 23,144,554\n","Non-trainable params: 86,976\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"lXslNLPZruaS"},"source":["a128_model = ran_model\n","\n","a128_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                   loss=tf.keras.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy'])\n","\n","\n","history = a128_model.fit(train_ds,\n","                         validation_data=val_ds,\n","                         epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ON-OSON-r2fj"},"source":["### Attention-164"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P2dT297er3BC","executionInfo":{"status":"ok","timestamp":1638629853704,"user_tz":300,"elapsed":9548,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"df57e372-8e41-4f86-8a80-4bc270791051"},"source":["ran_model = Attention164()\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"attention164\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_4 (Sequential)   (None, 32, 32, 3)         0         \n","                                                                 \n"," conv2d_1037 (Conv2D)        multiple                  864       \n","                                                                 \n"," batch_normalization_796 (Ba  multiple                 128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_796 (ReLU)            multiple                  0         \n","                                                                 \n"," max_pooling2d_53 (MaxPoolin  multiple                 0         \n"," g2D)                                                            \n","                                                                 \n"," residual_unit_246 (Residual  multiple                 19520     \n"," Unit)                                                           \n","                                                                 \n"," attention_module_24 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_25 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_26 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_27 (Attent  multiple                 452352    \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_295 (Residual  multiple                 96384     \n"," Unit)                                                           \n","                                                                 \n"," attention_module_28 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_29 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_30 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_31 (Attent  multiple                 1369216   \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_332 (Residual  multiple                 381184    \n"," Unit)                                                           \n","                                                                 \n"," attention_module_32 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_33 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_34 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," attention_module_35 (Attent  multiple                 3798528   \n"," ionModule)                                                      \n","                                                                 \n"," residual_unit_357 (Residual  multiple                 1516032   \n"," Unit)                                                           \n","                                                                 \n"," residual_unit_358 (Residual  multiple                 2171392   \n"," Unit)                                                           \n","                                                                 \n"," residual_unit_359 (Residual  multiple                 2171392   \n"," Unit)                                                           \n","                                                                 \n"," batch_normalization_1163 (B  multiple                 4096      \n"," atchNormalization)                                              \n","                                                                 \n"," re_lu_1163 (ReLU)           multiple                  0         \n","                                                                 \n"," average_pooling2d_5 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_5 (Flatten)         multiple                  0         \n","                                                                 \n"," dropout_3 (Dropout)         multiple                  0         \n","                                                                 \n"," dense_5 (Dense)             multiple                  10250     \n","                                                                 \n","=================================================================\n","Total params: 28,851,626\n","Trainable params: 28,740,330\n","Non-trainable params: 111,296\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"xN_rU059r3c5"},"source":["a164_model = ran_model\n","\n","a164_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                   loss=tf.keras.losses.CategoricalCrossentropy(), \n","                   metrics=['accuracy'])\n","\n","\n","history = a164_model.fit(train_ds,\n","                         validation_data=val_ds,\n","                         epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4o0wmU1_dsHG"},"source":[""],"execution_count":null,"outputs":[]}]}