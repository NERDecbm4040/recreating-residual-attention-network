{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"multi_arch-cifar10.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMY62bd1xbIF1p8jmJldSRb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rYJNBte6ywyx"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vt2mF-9ylH6","executionInfo":{"status":"ok","timestamp":1638508144039,"user_tz":300,"elapsed":2878,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"a6ade178-f46e-4e8e-ccf1-954c0427cae9"},"source":["# data processing\n","import numpy as np\n","import pandas as pd \n","from collections import defaultdict\n","\n","# data visualization\n","import seaborn as sns\n","%config InlineBackend.figure_format = 'retina'\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","from matplotlib import style\n","sns.set()\n","import urllib.request\n","\n","\n","import tensorflow as tf\n","print(tf.config.list_physical_devices('GPU'))\n","from tensorflow import keras\n","\n","# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Joy5pYymy1eS","executionInfo":{"status":"ok","timestamp":1638508144039,"user_tz":300,"elapsed":4,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"cc3cd4d8-1b34-4f66-e110-4498e178ed33"},"source":["# If using Google Colab\n","from google.colab import drive\n","BASE_PATH = '/content/drive'\n","drive.mount(BASE_PATH)\n","\n","# change directory\n","import os\n","PROJECT_PATH = os.path.join(BASE_PATH, \"MyDrive\", \"2021-09 Fall Semester\", \"ECBM 4040 Neural Network Deep Learning\", \"Project\", \"recreating-residual-attention-network\")\n","os.chdir(PROJECT_PATH)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"LvOmr1Eyy28a"},"source":["# Import created modules\n","from src.models.ResidualAttentionNetwork import ResidualAttentionNetwork, Attention56, Attention92\n","from src.utils import generate_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HsCtgLcy6Fa"},"source":["# Modelling"]},{"cell_type":"code","metadata":{"id":"4kL-cGAdy-Sv"},"source":["x_train, y_train, x_test, y_test, datagen = generate_data.get_cifar10(rotation_range=20,\n","                                                                      width_shift_range=0.2,\n","                                                                      height_shift_range=0.2,\n","                                                                      horizontal_flip=True,\n","                                                                      validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_GjVa2qzAkp"},"source":["INPUT_SHAPE = x_train.shape[1:]\n","NUM_CLASS = y_train.shape[1]\n","BATCH_SIZE = 256\n","N_EPOCH = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkDFCeNs5X2E"},"source":["## Naive Attention Learning vs Residual Attention Learning"]},{"cell_type":"markdown","metadata":{"id":"WYraP1xc5pkQ"},"source":["### Naive Attention Learning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzhK0LIjzDjy","executionInfo":{"status":"ok","timestamp":1638501301117,"user_tz":300,"elapsed":4173,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"9c1aed88-66db-4e31-fc5f-32739f95e959"},"source":["ran_model = ResidualAttentionNetwork(learning_type='nal')\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"residual_attention_network\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             multiple                  864       \n","                                                                 \n"," batch_normalization (BatchN  multiple                 128       \n"," ormalization)                                                   \n","                                                                 \n"," re_lu (ReLU)                multiple                  0         \n","                                                                 \n"," residual_unit (ResidualUnit  multiple                 6432      \n"," )                                                               \n","                                                                 \n"," attention_module (Attention  multiple                 116608    \n"," Module)                                                         \n","                                                                 \n"," residual_unit_13 (ResidualU  multiple                 24640     \n"," nit)                                                            \n","                                                                 \n"," attention_module_1 (Attenti  multiple                 347712    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_23 (ResidualU  multiple                 96384     \n"," nit)                                                            \n","                                                                 \n"," attention_module_2 (Attenti  multiple                 957184    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_30 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_31 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_32 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_106 (Ba  multiple                 2048      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_106 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d (AverageP  multiple                 0         \n"," ooling2D)                                                       \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  5130      \n","                                                                 \n","=================================================================\n","Total params: 3,028,362\n","Trainable params: 3,009,162\n","Non-trainable params: 19,200\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YkEBXW9Iy5sJ","executionInfo":{"status":"ok","timestamp":1638501860139,"user_tz":300,"elapsed":559026,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"0b8e6448-7dba-4e3e-bad5-88b0d6c4e966"},"source":["nal_model = ran_model\n","\n","nal_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = nal_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n","                        validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 73s 347ms/step - loss: 2.2965 - accuracy: 0.1332 - val_loss: 2.3498 - val_accuracy: 0.0999\n","Epoch 2/10\n","157/157 [==============================] - 50s 320ms/step - loss: 2.1305 - accuracy: 0.2123 - val_loss: 2.4616 - val_accuracy: 0.1332\n","Epoch 3/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.9824 - accuracy: 0.2711 - val_loss: 2.2443 - val_accuracy: 0.2018\n","Epoch 4/10\n","157/157 [==============================] - 50s 319ms/step - loss: 1.8942 - accuracy: 0.3067 - val_loss: 1.9455 - val_accuracy: 0.2913\n","Epoch 5/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.8331 - accuracy: 0.3316 - val_loss: 1.9147 - val_accuracy: 0.3196\n","Epoch 6/10\n","157/157 [==============================] - 50s 321ms/step - loss: 1.7814 - accuracy: 0.3485 - val_loss: 2.3502 - val_accuracy: 0.3234\n","Epoch 7/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.7305 - accuracy: 0.3649 - val_loss: 1.8189 - val_accuracy: 0.3385\n","Epoch 8/10\n","157/157 [==============================] - 50s 321ms/step - loss: 1.6849 - accuracy: 0.3857 - val_loss: 1.8450 - val_accuracy: 0.3535\n","Epoch 9/10\n","157/157 [==============================] - 51s 321ms/step - loss: 1.6495 - accuracy: 0.3964 - val_loss: 1.7107 - val_accuracy: 0.3771\n","Epoch 10/10\n","157/157 [==============================] - 51s 322ms/step - loss: 1.6179 - accuracy: 0.4110 - val_loss: 1.6644 - val_accuracy: 0.3986\n"]}]},{"cell_type":"code","metadata":{"id":"DMoo7v_Q5ti1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYSu67tk5uBy"},"source":["### Residual Attention Learning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3sr_o_E5erl","executionInfo":{"status":"ok","timestamp":1638501862869,"user_tz":300,"elapsed":2736,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"e6516922-1080-4d1a-c5bb-02e62eab5990"},"source":["ran_model = ResidualAttentionNetwork(learning_type='arl')\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"residual_attention_network_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_139 (Conv2D)         multiple                  864       \n","                                                                 \n"," batch_normalization_107 (Ba  multiple                 128       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_107 (ReLU)            multiple                  0         \n","                                                                 \n"," residual_unit_33 (ResidualU  multiple                 6432      \n"," nit)                                                            \n","                                                                 \n"," attention_module_3 (Attenti  multiple                 116608    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_46 (ResidualU  multiple                 24640     \n"," nit)                                                            \n","                                                                 \n"," attention_module_4 (Attenti  multiple                 347712    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_56 (ResidualU  multiple                 96384     \n"," nit)                                                            \n","                                                                 \n"," attention_module_5 (Attenti  multiple                 957184    \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_63 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_64 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," residual_unit_65 (ResidualU  multiple                 545024    \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_213 (Ba  multiple                 2048      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_213 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d_1 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_1 (Flatten)         multiple                  0         \n","                                                                 \n"," dense_1 (Dense)             multiple                  5130      \n","                                                                 \n","=================================================================\n","Total params: 3,028,362\n","Trainable params: 3,009,162\n","Non-trainable params: 19,200\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"fy88IU1bzNuq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638502418674,"user_tz":300,"elapsed":555810,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"dadd82ac-f018-4edb-d888-12dfc5c9d892"},"source":["arl_model = ran_model\n","\n","arl_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = arl_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n","                        validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 70s 343ms/step - loss: 2.1899 - accuracy: 0.1823 - val_loss: 2.6433 - val_accuracy: 0.1032\n","Epoch 2/10\n","157/157 [==============================] - 50s 319ms/step - loss: 1.9601 - accuracy: 0.2656 - val_loss: 2.8270 - val_accuracy: 0.1201\n","Epoch 3/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.8131 - accuracy: 0.3185 - val_loss: 2.4663 - val_accuracy: 0.2129\n","Epoch 4/10\n","157/157 [==============================] - 51s 321ms/step - loss: 1.7257 - accuracy: 0.3571 - val_loss: 1.7551 - val_accuracy: 0.3414\n","Epoch 5/10\n","157/157 [==============================] - 50s 318ms/step - loss: 1.6582 - accuracy: 0.3870 - val_loss: 1.7257 - val_accuracy: 0.3679\n","Epoch 6/10\n","157/157 [==============================] - 50s 319ms/step - loss: 1.6070 - accuracy: 0.4070 - val_loss: 1.9173 - val_accuracy: 0.3481\n","Epoch 7/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.5651 - accuracy: 0.4250 - val_loss: 1.6508 - val_accuracy: 0.4056\n","Epoch 8/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.5136 - accuracy: 0.4419 - val_loss: 1.5537 - val_accuracy: 0.4340\n","Epoch 9/10\n","157/157 [==============================] - 50s 320ms/step - loss: 1.4839 - accuracy: 0.4561 - val_loss: 1.5897 - val_accuracy: 0.4324\n","Epoch 10/10\n","157/157 [==============================] - 50s 318ms/step - loss: 1.4484 - accuracy: 0.4684 - val_loss: 1.6049 - val_accuracy: 0.4173\n"]}]},{"cell_type":"code","metadata":{"id":"bsebrvlmdvw8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_qf9aDeJ6JQH"},"source":["## Different number of attention module"]},{"cell_type":"markdown","metadata":{"id":"ZV1BC9vK6Y45"},"source":["In this part, the experiment is done using Residual Attention Learning mechanism"]},{"cell_type":"markdown","metadata":{"id":"XsOf7W_m6UZ5"},"source":["### Attention-56"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rc-qETCwmA6u","executionInfo":{"status":"ok","timestamp":1638508153455,"user_tz":300,"elapsed":4263,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"201906a4-6a49-4f69-a7d1-469ec72621af"},"source":["ran_model = Attention56()\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"attention56\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             multiple                  1728      \n","                                                                 \n"," batch_normalization (BatchN  multiple                 256       \n"," ormalization)                                                   \n","                                                                 \n"," re_lu (ReLU)                multiple                  0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  multiple                 0         \n"," )                                                               \n","                                                                 \n"," residual_unit (ResidualUnit  multiple                 75904     \n"," )                                                               \n","                                                                 \n"," attention_module (Attention  multiple                 1781248   \n"," Module)                                                         \n","                                                                 \n"," residual_unit_13 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," attention_module_1 (Attenti  multiple                 5433600   \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_23 (ResidualU  multiple                 1516032   \n"," nit)                                                            \n","                                                                 \n"," attention_module_2 (Attenti  multiple                 15133696  \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_30 (ResidualU  multiple                 6046720   \n"," nit)                                                            \n","                                                                 \n"," residual_unit_31 (ResidualU  multiple                 8668160   \n"," nit)                                                            \n","                                                                 \n"," residual_unit_32 (ResidualU  multiple                 8668160   \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_106 (Ba  multiple                 8192      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_106 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d (AverageP  multiple                 0         \n"," ooling2D)                                                       \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dropout (Dropout)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  20490     \n","                                                                 \n","=================================================================\n","Total params: 47,735,370\n","Trainable params: 47,658,698\n","Non-trainable params: 76,672\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":656},"id":"OJvbFVkB6fZb","executionInfo":{"status":"error","timestamp":1638505604846,"user_tz":300,"elapsed":1360320,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"e19aa2e3-5c48-4dc3-e44f-3c08824044a6"},"source":["a56_model = ran_model\n","\n","a56_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = a56_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n","                        validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","157/157 [==============================] - 250s 1s/step - loss: 2.4313 - accuracy: 0.1500 - val_loss: 2.4130 - val_accuracy: 0.0999\n","Epoch 2/10\n","157/157 [==============================] - 218s 1s/step - loss: 2.0335 - accuracy: 0.2475 - val_loss: 5.8116 - val_accuracy: 0.1016\n","Epoch 3/10\n","157/157 [==============================] - 218s 1s/step - loss: 1.7997 - accuracy: 0.3252 - val_loss: 11.2246 - val_accuracy: 0.1409\n","Epoch 4/10\n","157/157 [==============================] - 218s 1s/step - loss: 1.6848 - accuracy: 0.3762 - val_loss: 1.7482 - val_accuracy: 0.3559\n","Epoch 5/10\n","157/157 [==============================] - 218s 1s/step - loss: 1.5898 - accuracy: 0.4169 - val_loss: 3.1556 - val_accuracy: 0.2398\n","Epoch 6/10\n","157/157 [==============================] - 218s 1s/step - loss: 1.5175 - accuracy: 0.4482 - val_loss: 2.2535 - val_accuracy: 0.3431\n","Epoch 7/10\n"," 14/157 [=>............................] - ETA: 3:04 - loss: 1.4835 - accuracy: 0.4554"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c30e22d34913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m history = a56_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n\u001b[1;32m      9\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         epochs=N_EPOCH, verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"x6SBfflndtCy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9D6JZpv6fyS"},"source":["### Attention-92"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lzh4OviZ6fIv","executionInfo":{"status":"ok","timestamp":1638508164363,"user_tz":300,"elapsed":4504,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"f68ca095-e060-499f-f92b-50c8f7194a2c"},"source":["ran_model = Attention92()\n","inputs = tf.keras.Input((32, 32, 3))\n","ran_model(inputs)\n","ran_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"attention92\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_139 (Conv2D)         multiple                  1728      \n","                                                                 \n"," batch_normalization_107 (Ba  multiple                 256       \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_107 (ReLU)            multiple                  0         \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," residual_unit_33 (ResidualU  multiple                 75904     \n"," nit)                                                            \n","                                                                 \n"," attention_module_3 (Attenti  multiple                 1781248   \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_46 (ResidualU  multiple                 381184    \n"," nit)                                                            \n","                                                                 \n"," attention_module_4 (Attenti  multiple                 5433600   \n"," onModule)                                                       \n","                                                                 \n"," attention_module_5 (Attenti  multiple                 5433600   \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_65 (ResidualU  multiple                 1516032   \n"," nit)                                                            \n","                                                                 \n"," attention_module_6 (Attenti  multiple                 15133696  \n"," onModule)                                                       \n","                                                                 \n"," attention_module_7 (Attenti  multiple                 15133696  \n"," onModule)                                                       \n","                                                                 \n"," attention_module_8 (Attenti  multiple                 15133696  \n"," onModule)                                                       \n","                                                                 \n"," residual_unit_84 (ResidualU  multiple                 6046720   \n"," nit)                                                            \n","                                                                 \n"," residual_unit_85 (ResidualU  multiple                 8668160   \n"," nit)                                                            \n","                                                                 \n"," residual_unit_86 (ResidualU  multiple                 8668160   \n"," nit)                                                            \n","                                                                 \n"," batch_normalization_282 (Ba  multiple                 8192      \n"," tchNormalization)                                               \n","                                                                 \n"," re_lu_282 (ReLU)            multiple                  0         \n","                                                                 \n"," average_pooling2d_1 (Averag  multiple                 0         \n"," ePooling2D)                                                     \n","                                                                 \n"," flatten_1 (Flatten)         multiple                  0         \n","                                                                 \n"," dropout_1 (Dropout)         multiple                  0         \n","                                                                 \n"," dense_1 (Dense)             multiple                  20490     \n","                                                                 \n","=================================================================\n","Total params: 83,436,362\n","Trainable params: 83,298,762\n","Non-trainable params: 137,600\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"_V3KxO3T5zdv"},"source":["a92_model = ran_model\n","\n","a92_model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(), \n","                  metrics=['accuracy'])\n","\n","\n","history = a92_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'), \n","                        validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n","                        epochs=N_EPOCH, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4o0wmU1_dsHG"},"source":[""],"execution_count":null,"outputs":[]}]}